{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/overcoder/Library/Python/3.13/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/overcoder/Library/Python/3.13/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/overcoder/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-31T09:58:55.648821Z",
     "iopub.status.busy": "2025-10-31T09:58:55.648533Z",
     "iopub.status.idle": "2025-10-31T09:58:55.656293Z",
     "shell.execute_reply": "2025-10-31T09:58:55.655382Z",
     "shell.execute_reply.started": "2025-10-31T09:58:55.648802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# Cell 1 — Setup (MPS device, imports, seeds)\n",
    "# ================================================================\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:13.349271Z",
     "iopub.status.busy": "2025-10-31T10:02:13.348503Z",
     "iopub.status.idle": "2025-10-31T10:02:13.357683Z",
     "shell.execute_reply": "2025-10-31T10:02:13.357021Z",
     "shell.execute_reply.started": "2025-10-31T10:02:13.349247Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fasta file: Vista_Dataset/vista_sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — file locate (tries common Kaggle and /mnt/data)\n",
    "candidate_paths = [\n",
    "    \"/kaggle/input/vista-sequence/vista_sequences.fasta\",\n",
    "    \"Vista_Dataset/vista_sequences.fasta\",\n",
    "    \"/mnt/data/vista_sequence.fasta\",\n",
    "    \"/kaggle/working/vista_sequence.fasta\",\n",
    "    \"/kaggle/input/vista-enhancers/vista_sequence.fasta\",\n",
    "]\n",
    "fasta_path = None\n",
    "for p in candidate_paths:\n",
    "    if os.path.exists(p):\n",
    "        fasta_path = p\n",
    "        break\n",
    "if fasta_path is None:\n",
    "    raise FileNotFoundError(f\"vista_sequence.fasta not found. Tried paths:\\n\" + \"\\n\".join(candidate_paths))\n",
    "print(\"Using fasta file:\", fasta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:16.034003Z",
     "iopub.status.busy": "2025-10-31T10:02:16.033696Z",
     "iopub.status.idle": "2025-10-31T10:02:16.233289Z",
     "shell.execute_reply": "2025-10-31T10:02:16.232466Z",
     "shell.execute_reply.started": "2025-10-31T10:02:16.033963Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed sequences: 3408\n",
      "H: Human|chr16:86430087-86430726 | element 1 | positive  | neural tube[12/12] | hindbrain (rhombencephalon)[12/12] | limb[3/12] | cranial nerve[8/12]\n",
      "H: Human|chr16:85620095-85621736 | element 2 | negative\n",
      "H: Human|chr16:80423343-80424652 | element 3 | negative\n",
      "H: Human|chr16:80372593-80373755 | element 4 | positive  | neural tube[6/10] | hindbrain (rhombencephalon)[10/10] | midbrain (mesencephalon)[10/10]\n",
      "H: Human|chr16:79969907-79971297 | element 5 | negative\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — parse FASTA and build dataframe\n",
    "def parse_fasta_to_records(path):\n",
    "    # Expect fasta headers to include label/species; if not, you may need to adapt to your fasta header format.\n",
    "    records = []\n",
    "    with open(path, 'r') as fh:\n",
    "        header = None\n",
    "        seq_lines = []\n",
    "        for line in fh:\n",
    "            line=line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\">\"):\n",
    "                if header is not None:\n",
    "                    seq = \"\".join(seq_lines).upper()\n",
    "                    records.append((header, seq))\n",
    "                header = line[1:]\n",
    "                seq_lines = []\n",
    "            else:\n",
    "                seq_lines.append(line)\n",
    "        # last\n",
    "        if header is not None:\n",
    "            seq = \"\".join(seq_lines).upper()\n",
    "            records.append((header, seq))\n",
    "    return records\n",
    "\n",
    "records = parse_fasta_to_records(fasta_path)\n",
    "print(\"Parsed sequences:\", len(records))\n",
    "# Inspect a few headers to ensure label extraction\n",
    "for h,s in records[:5]:\n",
    "    print(\"H:\", h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:20.304265Z",
     "iopub.status.busy": "2025-10-31T10:02:20.303494Z",
     "iopub.status.idle": "2025-10-31T10:02:20.378785Z",
     "shell.execute_reply": "2025-10-31T10:02:20.378027Z",
     "shell.execute_reply.started": "2025-10-31T10:02:20.304236Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3408, 4)\n",
      "species\n",
      "human    2002\n",
      "mouse    1406\n",
      "Name: count, dtype: int64\n",
      "Enhancer flag counts: enhancer\n",
      "1    1750\n",
      "0    1658\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>sequence</th>\n",
       "      <th>species</th>\n",
       "      <th>enhancer</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human|chr16:86430087-86430726 | element 1 | po...</td>\n",
       "      <td>AACTGAAGGGACCCCGTTAGCATATAAACAAAAGGTGGGGGGTAGC...</td>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Human|chr16:85620095-85621736 | element 2 | ne...</td>\n",
       "      <td>GGCCCTGGTATGTTTGTTCTTCCAGGGGCTCCCAGGATGGATCCAG...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human|chr16:80423343-80424652 | element 3 | ne...</td>\n",
       "      <td>AAGATTGCCATTTGGGGTGTTTCTTGGGGCTAAGAACCATGAAGAC...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Human|chr16:80372593-80373755 | element 4 | po...</td>\n",
       "      <td>GTGACAGAGACAGACAGTGACAGAGACAGATTTTAGAATTTGAACA...</td>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Human|chr16:79969907-79971297 | element 5 | ne...</td>\n",
       "      <td>TGACACCCACTATTATCCAGTCCTTGATAAACCTCTTTATTTGTTC...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Human|chr16:79949950-79951518 | element 6 | ne...</td>\n",
       "      <td>AGTCACCCAGGTGGTAGTGGGCTGCAGATGCTGTGGGTTTTGTTTC...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Human|chr16:79026563-79028162 | element 7 | ne...</td>\n",
       "      <td>ACAGAAGCCTCAAGCCTAACCAACAAGAAAGATCACTTCATATGCA...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Human|chr16:78933253-78934686 | element 9 | ne...</td>\n",
       "      <td>TTGTTCCGGAAACCTAACTCCAAATCTTTGAACTTCCTAGAAACCT...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>1434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              header  \\\n",
       "0  Human|chr16:86430087-86430726 | element 1 | po...   \n",
       "1  Human|chr16:85620095-85621736 | element 2 | ne...   \n",
       "2  Human|chr16:80423343-80424652 | element 3 | ne...   \n",
       "3  Human|chr16:80372593-80373755 | element 4 | po...   \n",
       "4  Human|chr16:79969907-79971297 | element 5 | ne...   \n",
       "5  Human|chr16:79949950-79951518 | element 6 | ne...   \n",
       "6  Human|chr16:79026563-79028162 | element 7 | ne...   \n",
       "7  Human|chr16:78933253-78934686 | element 9 | ne...   \n",
       "\n",
       "                                            sequence species  enhancer  \\\n",
       "0  AACTGAAGGGACCCCGTTAGCATATAAACAAAAGGTGGGGGGTAGC...   human         1   \n",
       "1  GGCCCTGGTATGTTTGTTCTTCCAGGGGCTCCCAGGATGGATCCAG...   human         0   \n",
       "2  AAGATTGCCATTTGGGGTGTTTCTTGGGGCTAAGAACCATGAAGAC...   human         0   \n",
       "3  GTGACAGAGACAGACAGTGACAGAGACAGATTTTAGAATTTGAACA...   human         1   \n",
       "4  TGACACCCACTATTATCCAGTCCTTGATAAACCTCTTTATTTGTTC...   human         0   \n",
       "5  AGTCACCCAGGTGGTAGTGGGCTGCAGATGCTGTGGGTTTTGTTTC...   human         0   \n",
       "6  ACAGAAGCCTCAAGCCTAACCAACAAGAAAGATCACTTCATATGCA...   human         0   \n",
       "7  TTGTTCCGGAAACCTAACTCCAAATCTTTGAACTTCCTAGAAACCT...   human         0   \n",
       "\n",
       "   seq_len  \n",
       "0      640  \n",
       "1     1642  \n",
       "2     1310  \n",
       "3     1163  \n",
       "4     1391  \n",
       "5     1569  \n",
       "6     1600  \n",
       "7     1434  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4 — build dataframe with label extraction (try to infer from header)\n",
    "rows = []\n",
    "for header, seq in records:\n",
    "    h = header.lower()\n",
    "    # Best-effort inference:\n",
    "    if \"human\" in h or \"hs\" in h:\n",
    "        species = \"human\"\n",
    "    elif \"mouse\" in h or \"mm\" in h:\n",
    "        species = \"mouse\"\n",
    "    else:\n",
    "        # fallback: if file has species in separate field, split by '|' or whitespace:\n",
    "        species = \"unknown\"\n",
    "    # enhancer presence detection:\n",
    "    if \"enhancer\" in h or \"positive\" in h or \"pos\" in h:\n",
    "        enhancer_flag = 1\n",
    "    elif \"non\" in h or \"negative\" in h or \"neg\" in h or \"not\" in h:\n",
    "        enhancer_flag = 0\n",
    "    else:\n",
    "        # fallback: try numeric statuses\n",
    "        enhancer_flag = None\n",
    "    rows.append({\"header\": header, \"sequence\": seq, \"species\": species, \"enhancer\": enhancer_flag})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.shape)\n",
    "df['seq_len'] = df['sequence'].str.len()\n",
    "df.seq_len.describe()\n",
    "# If many 'unknown' or enhancer None, print sample to let user confirm header format:\n",
    "print(df['species'].value_counts(dropna=False))\n",
    "print(\"Enhancer flag counts:\", df['enhancer'].value_counts(dropna=False))\n",
    "df.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:23.800233Z",
     "iopub.status.busy": "2025-10-31T10:02:23.799561Z",
     "iopub.status.idle": "2025-10-31T10:02:23.856848Z",
     "shell.execute_reply": "2025-10-31T10:02:23.856171Z",
     "shell.execute_reply.started": "2025-10-31T10:02:23.800208Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhancer sequences (for scenario1): 1750\n",
      "class_s2\n",
      "2    1658\n",
      "0    1029\n",
      "1     721\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — filter & prepare labels for scenarios\n",
    "# Scenario 1: only enhancer sequences (paper's first scenario predicted human vs mouse among enhancers).\n",
    "df_enhancers = df[df['enhancer']==1].copy()\n",
    "print(\"Enhancer sequences (for scenario1):\", len(df_enhancers))\n",
    "\n",
    "# Scenario 2: all sequences -> classes: human_enhancer, mouse_enhancer, no_enhancer\n",
    "def class_label_row(r):\n",
    "    if r.enhancer==1 and r.species==\"human\":\n",
    "        return 0  # human enhancer\n",
    "    if r.enhancer==1 and r.species==\"mouse\":\n",
    "        return 1  # mouse enhancer\n",
    "    return 2      # no enhancer\n",
    "\n",
    "df['class_s2'] = df.apply(class_label_row, axis=1)\n",
    "print(df['class_s2'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:02:28.338628Z",
     "iopub.status.busy": "2025-10-31T10:02:28.338351Z",
     "iopub.status.idle": "2025-10-31T10:02:28.345738Z",
     "shell.execute_reply": "2025-10-31T10:02:28.345018Z",
     "shell.execute_reply.started": "2025-10-31T10:02:28.338609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 6 — encoding schemes\n",
    "INT_MAP = {'A':1,'C':3,'G':2,'T':4,'N':0}\n",
    "ATOMIC_MAP = {'A':70,'C':58,'G':78,'T':66,'N':0}\n",
    "EIIP_MAP = {'A':0.1260,'C':0.1340,'G':0.0806,'T':0.1335,'N':0.0}\n",
    "\n",
    "# BFDNA: per-sequence frequencies (the paper uses for each base the frequency across the whole sequence;\n",
    "# then every position mapped to that base's frequency value).\n",
    "def encode_sequence_integer(seq):\n",
    "    return [INT_MAP.get(b,0) for b in seq]\n",
    "\n",
    "def encode_sequence_atomic(seq):\n",
    "    return [ATOMIC_MAP.get(b,0) for b in seq]\n",
    "\n",
    "def encode_sequence_eiip(seq):\n",
    "    return [EIIP_MAP.get(b,0.0) for b in seq]\n",
    "\n",
    "def encode_sequence_bfdna(seq):\n",
    "    L = len(seq)\n",
    "    # count bases\n",
    "    counts = {'A':0,'C':0,'G':0,'T':0}\n",
    "    for b in seq:\n",
    "        if b in counts:\n",
    "            counts[b]+=1\n",
    "    freqs = {b: (counts[b]/L if L>0 else 0.0) for b in counts}\n",
    "    # map each position to its base frequency value (paper example uses this)\n",
    "    return [freqs.get(b,0.0) for b in seq]\n",
    "\n",
    "ENCODERS = {\n",
    "    'integer': encode_sequence_integer,\n",
    "    'atomic': encode_sequence_atomic,\n",
    "    'eiip': encode_sequence_eiip,\n",
    "    'bfdna': encode_sequence_bfdna\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:27.563993Z",
     "iopub.status.busy": "2025-10-31T10:05:27.563365Z",
     "iopub.status.idle": "2025-10-31T10:05:29.360531Z",
     "shell.execute_reply": "2025-10-31T10:05:29.359656Z",
     "shell.execute_reply.started": "2025-10-31T10:05:27.563955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFDNA shape (3408, 2000) maxlen 2000\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — prepare encoded arrays, pad sequences to max_len and min-max normalize per scheme\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def prepare_encoded_array(seqs, encoder_name, max_len_cap=2000):\n",
    "    \"\"\"Encode and pad sequences; truncate to max_len_cap to avoid OOM.\"\"\"\n",
    "    enc = ENCODERS[encoder_name]\n",
    "    encoded = [enc(s) for s in seqs]\n",
    "    # Cap very long sequences\n",
    "    if max_len_cap:\n",
    "        encoded = [x[:max_len_cap] for x in encoded]\n",
    "    max_len = max(len(x) for x in encoded)\n",
    "    padded = pad_sequences(encoded, maxlen=max_len, dtype='float32',\n",
    "                           padding='post', truncating='post', value=0.0)\n",
    "    # Min–max normalize across dataset\n",
    "    minv, maxv = padded.min(), padded.max()\n",
    "    if maxv > minv:\n",
    "        padded = (padded - minv) / (maxv - minv)\n",
    "    return padded, max_len\n",
    "\n",
    "# Example for BFDNA\n",
    "X_bfdna, maxlen_bfdna = prepare_encoded_array(df['sequence'].tolist(), 'bfdna')\n",
    "print(\"BFDNA shape\", X_bfdna.shape, \"maxlen\", maxlen_bfdna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:32.349161Z",
     "iopub.status.busy": "2025-10-31T10:05:32.348435Z",
     "iopub.status.idle": "2025-10-31T10:05:32.356337Z",
     "shell.execute_reply": "2025-10-31T10:05:32.355675Z",
     "shell.execute_reply.started": "2025-10-31T10:05:32.349130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 8 — helper: metric computations used in paper (CSI, G-mean)\n",
    "def classification_metrics(y_true, y_pred, average='binary'):\n",
    "    # y_true: 1d labels\n",
    "    # y_pred: 1d predicted labels\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    # compute confusion matrix elements (for binary)\n",
    "    if average=='binary' or len(np.unique(y_true))==2:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        # CSI = Precision + TPR - 1 (paper definition)\n",
    "        tpr = tp/(tp+fn) if (tp+fn)>0 else 0.0\n",
    "        csi = prec + tpr - 1\n",
    "        specificity = tn/(tn+fp) if (tn+fp)>0 else 0.0\n",
    "        gmean = math.sqrt(rec * specificity)\n",
    "    else:\n",
    "        # for multiclass, compute macro variants:\n",
    "        csi = None\n",
    "        gmean = None\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    return {'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'CSI':csi, 'G-mean':gmean, 'MCC':mcc, 'Kappa':kappa}\n",
    "\n",
    "# multiclass macro-average ROC AUC:\n",
    "def multiclass_roc_auc_score(y_true, y_proba, average=\"macro\"):\n",
    "    # y_true integer labels, y_proba: N x C\n",
    "    try:\n",
    "        return roc_auc_score(to_categorical(y_true), y_proba, average=average, multi_class='ovr')\n",
    "    except Exception as e:\n",
    "        print(\"roc_auc_score error:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:38.278702Z",
     "iopub.status.busy": "2025-10-31T10:05:38.278413Z",
     "iopub.status.idle": "2025-10-31T10:05:38.288239Z",
     "shell.execute_reply": "2025-10-31T10:05:38.287518Z",
     "shell.execute_reply.started": "2025-10-31T10:05:38.278681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 9 — model builders (scenario1: binary, scenario2: multiclass)\n",
    "def build_bilstm_scenario1(input_shape):\n",
    "    # paper: 256 BiLSTM -> dropout .15 -> 128 BiLSTM -> dropout .2 -> 64 BiLSTM -> dropout .2\n",
    "    # SeLU activations; BatchNorm; Flatten; Dense 512,256,128; Sigmoid output\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, activation='tanh'))(inp)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.15, seed=SEED)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, activation='tanh'))(x)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.20, seed=SEED)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, activation='tanh'))(x)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.20, seed=SEED)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='selu')(x)\n",
    "    x = layers.Dense(256, activation='selu')(x)\n",
    "    x = layers.Dense(128, activation='selu')(x)\n",
    "    out = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_bilstm_scenario2(input_shape, n_classes):\n",
    "    # paper: 128 BiLSTM -> dropout .15 -> 64 BiLSTM -> dropout .2 -> BatchNorm -> Flatten -> Dense 256,128 -> Softmax\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, activation='tanh'))(inp)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.15, seed=SEED)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, activation='tanh'))(x)\n",
    "    x = layers.Activation('selu')(x)\n",
    "    x = layers.Dropout(0.20, seed=SEED)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='selu')(x)\n",
    "    x = layers.Dense(128, activation='selu')(x)\n",
    "    out = layers.Dense(n_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:41.572877Z",
     "iopub.status.busy": "2025-10-31T10:05:41.572596Z",
     "iopub.status.idle": "2025-10-31T10:05:41.584563Z",
     "shell.execute_reply": "2025-10-31T10:05:41.584036Z",
     "shell.execute_reply.started": "2025-10-31T10:05:41.572858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 10 — training helper to train and evaluate a model; returns history and metrics\n",
    "def train_and_evaluate_model(X, y, scenario=1, encoder_name='bfdna', batch_size=32, epochs=500):\n",
    "    # X: padded 2D array (samples, seq_len). We'll reshape to (samples, seq_len, 1)\n",
    "    X3 = np.expand_dims(X, -1)\n",
    "    if scenario == 1:\n",
    "        # binary: y are species labels for enhancer-only samples (human=0, mouse=1)\n",
    "        y_bin = y  # should be 0/1\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X3, y_bin, test_size=0.30, random_state=SEED, stratify=y_bin)\n",
    "        # split temp into val/test equally: 0.15 each of full\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=y_temp)\n",
    "        model = build_bilstm_scenario1(input_shape=X3.shape[1:])\n",
    "        opt = optimizers.RMSprop()\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    else:\n",
    "        # multi-class: y are 0..C-1\n",
    "        n_classes = len(np.unique(y))\n",
    "        y_cat = to_categorical(y, num_classes=n_classes)\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X3, y_cat, test_size=0.30, random_state=SEED, stratify=y)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED, stratify=np.argmax(y_temp, axis=1))\n",
    "        model = build_bilstm_scenario2(input_shape=X3.shape[1:], n_classes=n_classes)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks\n",
    "    outdir = f\"./outputs/{encoder_name}/scenario{scenario}\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    ckpt = callbacks.ModelCheckpoint(os.path.join(outdir, \"best_model.h5\"), monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    csvlog = callbacks.CSVLogger(os.path.join(outdir, \"training_log.csv\"))\n",
    "    # Paper trained full 500 epochs — we avoid EarlyStopping to be faithful, but you can enable it.\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[ckpt, csvlog], verbose=2)\n",
    "    # load best\n",
    "    model.load_weights(os.path.join(outdir, \"best_model.h5\"))\n",
    "    # Predict\n",
    "    if scenario==1:\n",
    "        y_pred_prob = model.predict(X_test).ravel()\n",
    "        y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "        y_true = y_test\n",
    "    else:\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # metrics\n",
    "    results = {}\n",
    "    if scenario==1:\n",
    "        auc_score = roc_auc_score(y_true, y_pred_prob)\n",
    "        m = classification_metrics(y_true, y_pred, average='binary')\n",
    "        m['AUC'] = auc_score\n",
    "        results = m\n",
    "    else:\n",
    "        auc_score = multiclass_roc_auc_score(y_true, y_pred_prob)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        # For CSI and G-mean paper printed single scores; we will leave CSI/G-mean as None for multiclass (could compute per-class)\n",
    "        results = {'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'CSI':None, 'G-mean':None, 'MCC':mcc, 'Kappa':kappa, 'AUC':auc_score}\n",
    "\n",
    "    # save predictions & test y\n",
    "    np.savez(os.path.join(outdir, \"test_preds_and_truth.npz\"), y_true=y_true, y_pred=y_pred, y_pred_prob=y_pred_prob)\n",
    "    # save training history\n",
    "    pd.DataFrame(history.history).to_csv(os.path.join(outdir, \"history.csv\"), index=False)\n",
    "    return model, history, results, (X_test, y_test, y_pred, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T10:05:44.999279Z",
     "iopub.status.busy": "2025-10-31T10:05:44.998599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Encoder: integer\n",
      "Training Scenario 1 (human vs mouse enhancers) for encoder integer\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_loss improved from None to 2.63610, saving model to ./outputs/integer/scenario1/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 - 288s - 4s/step - accuracy: 0.5184 - loss: 3.4620 - val_accuracy: 0.4122 - val_loss: 2.6361\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_loss did not improve from 2.63610\n",
      "77/77 - 317s - 4s/step - accuracy: 0.5429 - loss: 1.1237 - val_accuracy: 0.5878 - val_loss: 3.2987\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_loss improved from 2.63610 to 2.53238, saving model to ./outputs/integer/scenario1/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 - 360s - 5s/step - accuracy: 0.4971 - loss: 1.0098 - val_accuracy: 0.4122 - val_loss: 2.5324\n",
      "Epoch 4/10\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 — full pipeline loop over encoders and both scenarios (warning: heavy; you can run one encoder at a time)\n",
    "encoders = ['integer','atomic','eiip','bfdna']\n",
    "all_results = {'scenario1':{}, 'scenario2':{}}\n",
    "for encoder in encoders:\n",
    "    print(\"\\n\\n### Encoder:\", encoder)\n",
    "    X, _ = prepare_encoded_array(df['sequence'].tolist(), encoder)\n",
    "    # Scenario 1 uses only enhancer sequences and species labels among enhancers\n",
    "    df_e = df[df['enhancer']==1].reset_index(drop=True)\n",
    "    X_e, _ = prepare_encoded_array(df_e['sequence'].tolist(), encoder)\n",
    "    # species mapping among enhancers:\n",
    "    species_map = df_e['species'].map({'human':0,'mouse':1}).fillna(0).astype(int).values\n",
    "    # Train scenario1\n",
    "    print(\"Training Scenario 1 (human vs mouse enhancers) for encoder\", encoder)\n",
    "    model1, hist1, res1, testinfo1 = train_and_evaluate_model(X_e, species_map, scenario=1, encoder_name=encoder, batch_size=16, epochs=10)\n",
    "    all_results['scenario1'][encoder] = res1\n",
    "    print(\"Scenario1 results:\", res1)\n",
    "    # Scenario2: multiclass\n",
    "    print(\"Training Scenario 2 (human enhancer / mouse enhancer / no enhancer) for encoder\", encoder)\n",
    "    # class_s2 in df already (0 human enh,1 mouse enh,2 no enhancer)\n",
    "    X_all, _ = prepare_encoded_array(df['sequence'].tolist(), encoder)\n",
    "    classes_s2 = df['class_s2'].values\n",
    "    model2, hist2, res2, testinfo2 = train_and_evaluate_model(X_all, classes_s2, scenario=2, encoder_name=encoder, batch_size=32, epochs=10)\n",
    "    all_results['scenario2'][encoder] = res2\n",
    "    print(\"Scenario2 results:\", res2)\n",
    "    # Save intermediate results\n",
    "    pd.DataFrame(all_results).to_csv(f\"./outputs/{encoder}_summary_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 12 — plotting helpers (example: training curves, ROC, confusion matrix)\n",
    "import itertools\n",
    "def plot_training(history_csv_path=None, history_obj=None, outpath=None):\n",
    "    if history_obj is not None:\n",
    "        history = history_obj.history\n",
    "    else:\n",
    "        history = pd.read_csv(history_csv_path).to_dict()\n",
    "    plt.figure(figsize=(10,4))\n",
    "    if 'loss' in history:\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(history['loss'], label='train_loss')\n",
    "        plt.plot(history['val_loss'], label='val_loss')\n",
    "        plt.legend(); plt.title(\"Loss\")\n",
    "    if 'accuracy' in history:\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(history['accuracy'], label='train_acc')\n",
    "        plt.plot(history['val_accuracy'], label='val_acc')\n",
    "        plt.legend(); plt.title(\"Accuracy\")\n",
    "    if outpath:\n",
    "        plt.savefig(outpath)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues, outpath=None):\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
    "    plt.ylabel('True label'); plt.xlabel('Predicted label'); plt.title(title)\n",
    "    if outpath:\n",
    "        plt.savefig(outpath)\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_binary(y_true, y_prob, outpath=None):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC'); plt.legend()\n",
    "    if outpath:\n",
    "        plt.savefig(outpath)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8617971,
     "sourceId": 13566704,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
